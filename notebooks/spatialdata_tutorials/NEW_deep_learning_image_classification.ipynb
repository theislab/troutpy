{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.local/lib/python3.10/site-packages/dask/dataframe/__init__.py:31: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
      "  warnings.warn(\n",
      "/home/sergio/.local/lib/python3.10/site-packages/numba/core/decorators.py:246: RuntimeWarning: nopython is set for njit and is ignored\n",
      "  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from anndata import AnnData\n",
    "from monai.networks.nets import DenseNet121\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from spatial_image import SpatialImage\n",
    "from spatialdata import SpatialData, read_zarr, transform\n",
    "from spatialdata.dataloader.datasets import ImageTilesDataset\n",
    "from spatialdata.transformations import get_transformation\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "mp.set_start_method(\"spawn\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.local/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import spatialdata_io\n",
    "import spatialdata as sd\n",
    "\n",
    "# while not pip installable, add path to file \n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import exrna "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read spatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.local/lib/python3.10/site-packages/zarr/creation.py:614: UserWarning: ignoring keyword argument 'read_only'\n",
      "  compressor, fill_value = _kwargs_compat(compressor, fill_value, kwargs)\n",
      "/home/sergio/.local/lib/python3.10/site-packages/zarr/creation.py:614: UserWarning: ignoring keyword argument 'read_only'\n",
      "  compressor, fill_value = _kwargs_compat(compressor, fill_value, kwargs)\n",
      "/home/sergio/.local/lib/python3.10/site-packages/zarr/creation.py:614: UserWarning: ignoring keyword argument 'read_only'\n",
      "  compressor, fill_value = _kwargs_compat(compressor, fill_value, kwargs)\n",
      "/home/sergio/.local/lib/python3.10/site-packages/zarr/creation.py:614: UserWarning: ignoring keyword argument 'read_only'\n",
      "  compressor, fill_value = _kwargs_compat(compressor, fill_value, kwargs)\n",
      "/home/sergio/.local/lib/python3.10/site-packages/zarr/creation.py:614: UserWarning: ignoring keyword argument 'read_only'\n",
      "  compressor, fill_value = _kwargs_compat(compressor, fill_value, kwargs)\n",
      "/home/sergio/.local/lib/python3.10/site-packages/zarr/creation.py:614: UserWarning: ignoring keyword argument 'read_only'\n",
      "  compressor, fill_value = _kwargs_compat(compressor, fill_value, kwargs)\n"
     ]
    }
   ],
   "source": [
    "xenium_path_cropped='/media/sergio/Discovair_final/mousebrain_prime_crop_points2regions_annotated.zarr'\n",
    "output_path='/media/sergio/Discovair_final/analysis_crop'\n",
    "sdata=sd.read_zarr(xenium_path_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CA'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circles=sdata['cell_circles']\n",
    "xenium_circles_diameter = 2 * np.mean(circles.radius)\n",
    "cell_types = sdata[\"table\"].obs[\"cell type\"].cat.categories.tolist()\n",
    "sdata[\"table\"].obs['cell type'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS Fuction should be define outside of the code\n",
    "# def my_transform(sdata: sd.SpatialData) -> tuple[torch.tensor, torch.tensor]:\n",
    "    tile = sdata['morphology'].compute()\n",
    "    tile = torch.tensor(tile)\n",
    "    \n",
    "    expected_category = sdata[\"table\"].obs['cell type'].values[0]\n",
    "    expected_category = cell_types.index(expected_category)\n",
    "    cell_type = F.one_hot(\n",
    "        torch.tensor(expected_category), num_classes=len(cell_types)\n",
    "    )\n",
    "    return tile, cell_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1149156/2667757561.py:1: DeprecationWarning: Table accessor will be deprecated with SpatialData version 0.1, use sdata.tables instead.\n",
      "  sdata['table']=sdata.table[sdata.table.obs['cell_id'].isin(sdata['cell_circles'].index)]\n",
      "/home/sergio/.local/lib/python3.10/site-packages/spatialdata/_core/_elements.py:116: UserWarning: Key `table` already exists. Overwriting it in-memory.\n",
      "  self._check_key(key, self.keys(), self._shared_keys)\n",
      "/tmp/ipykernel_1149156/2667757561.py:2: DeprecationWarning: Table accessor will be deprecated with SpatialData version 0.1, use sdata.tables instead.\n",
      "  sdata['cell_circles']=sdata['cell_circles'][sdata['cell_circles'].index.isin(sdata.table.obs['cell_id'])]\n",
      "/home/sergio/.local/lib/python3.10/site-packages/spatialdata/_core/_elements.py:96: UserWarning: Key `cell_circles` already exists. Overwriting it in-memory.\n",
      "  self._check_key(key, self.keys(), self._shared_keys)\n"
     ]
    }
   ],
   "source": [
    "sdata['table']=sdata.table[sdata.table.obs['cell_id'].isin(sdata['cell_circles'].index)]\n",
    "sdata['cell_circles']=sdata['cell_circles'][sdata['cell_circles'].index.isin(sdata.table.obs['cell_id'])]\n",
    "sdata['morphology']=sdata['morphology_focus'].scale0.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exrna.pp import my_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.local/lib/python3.10/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# let's import the above function\n",
    "#from densenet_utils import my_transform\n",
    "\n",
    "dataset = ImageTilesDataset(\n",
    "    sdata=sdata,\n",
    "    regions_to_images={\"cell_circles\": \"morphology\"},\n",
    "    regions_to_coordinate_systems={\"cell_circles\": \"global\"},\n",
    "    table_name=\"table\",\n",
    "    tile_dim_in_units=3 * xenium_circles_diameter,\n",
    "    transform=my_transform,\n",
    "    rasterize=True,\n",
    "    rasterize_kwargs={\"target_width\": 32},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function exrna.pp.format.my_transform(sdata: spatialdata._core.spatialdata.SpatialData) -> tuple[torch._VariableFunctionsClass.tensor, torch._VariableFunctionsClass.tensor]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TilesDataModule(LightningDataModule):\n",
    "    def __init__(self, batch_size: int, num_workers: int, dataset: torch.utils.data.Dataset):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        n_train = int(len(self.dataset) * 0.7)\n",
    "        n_val = int(len(self.dataset) * 0.2)\n",
    "        n_test = len(self.dataset) - n_train - n_val\n",
    "        self.train, self.val, self.test = torch.utils.data.random_split(\n",
    "            self.dataset,\n",
    "            [n_train, n_val, n_test],\n",
    "            generator=torch.Generator().manual_seed(42),\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNetModel(pl.LightningModule):\n",
    "    def __init__(self, learning_rate: float, in_channels: int, num_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # store hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.loss_function = CrossEntropyLoss()\n",
    "\n",
    "        # make the model\n",
    "        self.model = DenseNet121(spatial_dims=2, in_channels=in_channels, out_channels=num_classes)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def _compute_loss_from_batch(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> float:\n",
    "        inputs = batch[0]\n",
    "        labels = batch[1]\n",
    "\n",
    "        outputs = self.model(inputs)\n",
    "        return self.loss_function(outputs, labels)\n",
    "\n",
    "    def training_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> Dict[str, float]:\n",
    "        # compute the loss\n",
    "        loss = self._compute_loss_from_batch(batch=batch, batch_idx=batch_idx)\n",
    "\n",
    "        # perform logging\n",
    "        self.log(\"training_loss\", loss, batch_size=len(batch[0]))\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> float:\n",
    "        loss = self._compute_loss_from_batch(batch=batch, batch_idx=batch_idx)\n",
    "\n",
    "        imgs, labels = batch\n",
    "        acc = self.compute_accuracy(imgs, labels)\n",
    "        # By default logs it per epoch (weighted average over batches), and returns it afterwards\n",
    "        self.log(\"test_acc\", acc)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        acc = self.compute_accuracy(imgs, labels)\n",
    "        # By default logs it per epoch (weighted average over batches), and returns it afterwards\n",
    "        self.log(\"test_acc\", acc)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx: int, dataloader_idx: int = 0):\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs).argmax(dim=-1)\n",
    "        return preds\n",
    "\n",
    "    def compute_accuracy(self, imgs, labels):\n",
    "        preds = self.model(imgs).argmax(dim=-1)\n",
    "        labels_value = torch.argmax(labels, dim=-1)\n",
    "        acc = (labels_value == preds).float().mean()\n",
    "        return acc\n",
    "\n",
    "    def configure_optimizers(self) -> Adam:\n",
    "        return Adam(self.model.parameters(), lr=self.hparams.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4096 batch size.\n",
      "Using 10 workers.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/namedarray/core.py:433\u001b[0m, in \u001b[0;36mNamedArray.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m test_dl \u001b[38;5;241m=\u001b[39m tiles_data_module\u001b[38;5;241m.\u001b[39mtest_dataloader()\n\u001b[1;32m     26\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(cell_types)\n\u001b[0;32m---> 27\u001b[0m in_channels \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m DenseNetModel(\n\u001b[1;32m     30\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m,\n\u001b[1;32m     31\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39min_channels,\n\u001b[1;32m     32\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39mnum_classes,\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/spatialdata/dataloader/datasets.py:371\u001b[0m, in \u001b[0;36mImageTilesDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(idx, tile)\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(idx, tile)\n",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m, in \u001b[0;36mmy_transform\u001b[0;34m(sdata)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmy_transform\u001b[39m(sdata: sd\u001b[38;5;241m.\u001b[39mSpatialData) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mtensor, torch\u001b[38;5;241m.\u001b[39mtensor]:\n\u001b[1;32m      2\u001b[0m     tile \u001b[38;5;241m=\u001b[39m sdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmorphology_focus\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m----> 3\u001b[0m     tile \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     expected_category \u001b[38;5;241m=\u001b[39m sdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m     expected_category \u001b[38;5;241m=\u001b[39m cell_types\u001b[38;5;241m.\u001b[39mindex(expected_category)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/core/dataarray.py:768\u001b[0m, in \u001b[0;36mDataArray.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/namedarray/core.py:435\u001b[0m, in \u001b[0;36mNamedArray.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen() of unsized object\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchvision\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "pl.seed_everything(7)\n",
    "\n",
    "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \"..\")\n",
    "BATCH_SIZE = 4096 if torch.cuda.is_available() else 64\n",
    "NUM_WORKERS = 10 if torch.cuda.is_available() else 8\n",
    "print(f\"Using {BATCH_SIZE} batch size.\")\n",
    "print(f\"Using {NUM_WORKERS} workers.\")\n",
    "\n",
    "tiles_data_module = TilesDataModule(batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, dataset=dataset)\n",
    "\n",
    "tiles_data_module.setup()\n",
    "train_dl = tiles_data_module.train_dataloader()\n",
    "val_dl = tiles_data_module.val_dataloader()\n",
    "test_dl = tiles_data_module.test_dataloader()\n",
    "\n",
    "num_classes = len(cell_types)\n",
    "in_channels = dataset[0][0].shape[0]\n",
    "\n",
    "model = DenseNetModel(\n",
    "    learning_rate=1e-5,\n",
    "    in_channels=in_channels,\n",
    "    num_classes=num_classes,\n",
    ")\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=2,\n",
    "    accelerator=\"auto\",\n",
    "    # devices=1,  # limiting got iPython runs. Edit: it works also without now\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    "    callbacks=[\n",
    "        LearningRateMonitor(logging_interval=\"step\"),\n",
    "        TQDMProgressBar(refresh_rate=5),\n",
    "    ],\n",
    "    log_every_n_steps=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial_exrna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
